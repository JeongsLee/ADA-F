
# Universal Approximators from Anti-Derivatives: Enhancing Neural Networks
Jeongsu Lee

Department of mechanical, smart, and industrial engineering, Gachon University, Seongnam 13120, South Korea
Corresponding authors: leejeongsu@gachon.ac.kr 

The existence of optimal neural networks, represented as combinations of piecewise functions, is proven by the universal approximation theorem. However, deriving this optimal solution from the training parameters of neural networks remains a challenging problem. This study proposes a novel strategy to construct an approximator for an arbitrary function, starting with a presumed optimal piecewise solution. The proposed approximation employs the anti-derivatives of a Fourier series expansion for the presumed piecewise function, leading to a remarkable feature that enables the simultaneous approximation of an arbitrary function and its anti-derivatives. Systematic experiments have demonstrated the outstanding merits of the proposed anti-derivatives-based approximator, such as the ability to solve differential equations and to enhance the capabilities of neural networks. Furthermore, the anti-derivatives approximator allows for the optimization of activation profiles within neural networks. This feature introduces a novel approach for finding unconventional activation profiles specialized for a given dataset.
